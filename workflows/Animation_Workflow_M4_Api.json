{
  "1": {
    "inputs": {
      "ckpt_name": "animagine-xl-3.1.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "2": {
    "inputs": {
      "text": "(masterpiece), score_9,\nclean black ink line art,\nperfect smooth continuous lines,\nsingle unbroken stroke,\nuniform line thickness,\nbold solid black outlines,\npure white background,\nno texture,\nno shading,\nno color,\nvector-style line art,\nanimation clean-up quality,\nstudio inked frame,\nconsistent stroke weight,\nprecise geometry,\nstable silhouette,\nno wobble,\nno jitter,\nprofessional animation linework\n",
      "clip": [
        "89",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "3": {
    "inputs": {
      "text": "score_4, score_5, score_6,\ncolor, colors, colored lines,\nshading, shadows, gradients,\nsketch, rough sketch, pencil,\nconstruction lines, guidelines,\ntexture, paper texture, noise,\nhalftone, screen tone, dots,\ncrosshatching, hatching,\nmessy lines, broken lines,\nvariable line weight,\ndouble lines, fuzzy edges,\nblur, lowres,\nrealistic, 3d render,\npainted, watercolor, pastel,\ngray, grayscale, grey,\nbackground clutter\n",
      "clip": [
        "89",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "5": {
    "inputs": {
      "seed": 153563715982477,
      "steps": 40,
      "cfg": 9,
      "sampler_name": "dpmpp_2m_sde_gpu",
      "scheduler": "karras",
      "denoise": 0.8,
      "model": [
        "66",
        0
      ],
      "positive": [
        "104",
        0
      ],
      "negative": [
        "104",
        1
      ],
      "latent_image": [
        "65",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "41": {
    "inputs": {
      "samples": [
        "55",
        0
      ],
      "vae": [
        "1",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "55": {
    "inputs": {
      "seed": 153563715982370,
      "steps": 50,
      "cfg": 9,
      "sampler_name": "dpmpp_2m_sde_gpu",
      "scheduler": "karras",
      "denoise": 0.5,
      "model": [
        "105",
        0
      ],
      "positive": [
        "77",
        0
      ],
      "negative": [
        "76",
        0
      ],
      "latent_image": [
        "5",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "65": {
    "inputs": {
      "pixels": [
        "96",
        0
      ],
      "vae": [
        "1",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "66": {
    "inputs": {
      "weight": 0.4,
      "weight_type": "linear",
      "combine_embeds": "concat",
      "start_at": 0,
      "end_at": 0.6,
      "embeds_scaling": "K+V",
      "model": [
        "89",
        0
      ],
      "ipadapter": [
        "68",
        0
      ],
      "image": [
        "87",
        0
      ],
      "clip_vision": [
        "69",
        0
      ]
    },
    "class_type": "IPAdapterAdvanced",
    "_meta": {
      "title": "IPAdapter Advanced"
    }
  },
  "68": {
    "inputs": {
      "ipadapter_file": "ip-adapter-plus_sdxl_vit-h.safetensors"
    },
    "class_type": "IPAdapterModelLoader",
    "_meta": {
      "title": "IPAdapter Model Loader"
    }
  },
  "69": {
    "inputs": {
      "clip_name": "CLIP-ViT-H-14-laion2B-s32b-b79k.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "72": {
    "inputs": {
      "image": "ComfyUI_00004_.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "73": {
    "inputs": {
      "samples": [
        "5",
        0
      ],
      "vae": [
        "1",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "76": {
    "inputs": {
      "text": "jagged lines,\nwobble,\nedge noise,\nmicro jitter,\nuneven stroke,\nthick-thin variation,\nink bleed,\nbroken curves,\nover-sharpening,\naliasing,\npixel noise,\ntexture residue\n",
      "clip": [
        "89",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "77": {
    "inputs": {
      "text": "ultra-clean vector ink,\nperfectly smooth curves,\nclosed shapes,\neven stroke thickness,\nhigh contrast black on white,\nanimation final pass,\ninking pass,\nno artifacts,\nno deformation,\nno distortion,\nconsistent line continuity,\nprofessional cel animation linework\n",
      "clip": [
        "89",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "78": {
    "inputs": {
      "detect_hand": "enable",
      "detect_body": "enable",
      "detect_face": "enable",
      "resolution": 1920,
      "bbox_detector": "yolox_l.onnx",
      "pose_estimator": "dw-ll_ucoco_384_bs5.torchscript.pt",
      "scale_stick_for_xinsr_cn": "disable",
      "image": [
        "96",
        0
      ]
    },
    "class_type": "DWPreprocessor",
    "_meta": {
      "title": "DWPose Estimator"
    }
  },
  "87": {
    "inputs": {
      "interpolation": "BICUBIC",
      "crop_position": "pad",
      "sharpening": 0,
      "image": [
        "72",
        0
      ]
    },
    "class_type": "PrepImageForClipVision",
    "_meta": {
      "title": "Prep Image For ClipVision"
    }
  },
  "89": {
    "inputs": {
      "lora_name": "lora_rough_to_clean_sdxl_v1.safetensors",
      "strength_model": 0,
      "strength_clip": 0,
      "model": [
        "97",
        0
      ],
      "clip": [
        "1",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "96": {
    "inputs": {
      "directory": "m4_test_images",
      "image_load_cap": 0,
      "skip_first_images": 0,
      "select_every_nth": 1
    },
    "class_type": "VHS_LoadImages",
    "_meta": {
      "title": "Load Images (Upload) ğŸ¥ğŸ…¥ğŸ…—ğŸ…¢"
    }
  },
  "97": {
    "inputs": {
      "model_name": "mm_sdxl_v10_beta.ckpt",
      "beta_schedule": "linear (AnimateDiff-SDXL)",
      "model": [
        "1",
        0
      ],
      "context_options": [
        "98",
        0
      ]
    },
    "class_type": "ADE_AnimateDiffLoaderGen1",
    "_meta": {
      "title": "AnimateDiff Loader ğŸ­ğŸ…ğŸ…“â‘ "
    }
  },
  "98": {
    "inputs": {
      "context_length": 4,
      "context_stride": 1,
      "context_overlap": 1,
      "fuse_method": "pyramid",
      "use_on_equal_length": false,
      "start_percent": 0,
      "guarantee_steps": 1
    },
    "class_type": "ADE_StandardUniformContextOptions",
    "_meta": {
      "title": "Context Optionsâ—†Standard Uniform ğŸ­ğŸ…ğŸ…“"
    }
  },
  "99": {
    "inputs": {
      "frame_rate": 30,
      "loop_count": 0,
      "filename_prefix": "AnimateDiff",
      "format": "image/gif",
      "pingpong": false,
      "save_output": true,
      "images": [
        "41",
        0
      ],
      "vae": [
        "1",
        2
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "Video Combine ğŸ¥ğŸ…¥ğŸ…—ğŸ…¢"
    }
  },
  "100": {
    "inputs": {
      "frame_rate": 30,
      "loop_count": 0,
      "filename_prefix": "AnimateDiff",
      "format": "image/gif",
      "pingpong": false,
      "save_output": true,
      "images": [
        "73",
        0
      ],
      "vae": [
        "1",
        2
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "Video Combine ğŸ¥ğŸ…¥ğŸ…—ğŸ…¢"
    }
  },
  "101": {
    "inputs": {
      "cnet": "controlnet_xl_union_xinsir.safetensors"
    },
    "class_type": "ACN_ControlNetLoaderAdvanced",
    "_meta": {
      "title": "Load Advanced ControlNet Model ğŸ›‚ğŸ…ğŸ…’ğŸ…"
    }
  },
  "102": {
    "inputs": {
      "cnet": "controlnet_openpose_sdxl.safetensors"
    },
    "class_type": "ACN_ControlNetLoaderAdvanced",
    "_meta": {
      "title": "Load Advanced ControlNet Model ğŸ›‚ğŸ…ğŸ…’ğŸ…"
    }
  },
  "103": {
    "inputs": {
      "strength": 1,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "2",
        0
      ],
      "negative": [
        "3",
        0
      ],
      "control_net": [
        "101",
        0
      ],
      "image": [
        "96",
        0
      ],
      "vae_optional": [
        "1",
        2
      ]
    },
    "class_type": "ACN_AdvancedControlNetApply_v2",
    "_meta": {
      "title": "Apply Advanced ControlNet ğŸ›‚ğŸ…ğŸ…’ğŸ…"
    }
  },
  "104": {
    "inputs": {
      "strength": 1,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "103",
        0
      ],
      "negative": [
        "103",
        1
      ],
      "control_net": [
        "102",
        0
      ],
      "image": [
        "78",
        0
      ],
      "vae_optional": [
        "1",
        2
      ]
    },
    "class_type": "ACN_AdvancedControlNetApply_v2",
    "_meta": {
      "title": "Apply Advanced ControlNet ğŸ›‚ğŸ…ğŸ…’ğŸ…"
    }
  },
  "105": {
    "inputs": {
      "weight": 0.2,
      "weight_type": "linear",
      "combine_embeds": "concat",
      "start_at": 0,
      "end_at": 0.6,
      "embeds_scaling": "K+V",
      "model": [
        "89",
        0
      ],
      "ipadapter": [
        "68",
        0
      ],
      "image": [
        "87",
        0
      ],
      "clip_vision": [
        "69",
        0
      ]
    },
    "class_type": "IPAdapterAdvanced",
    "_meta": {
      "title": "IPAdapter Advanced"
    }
  }
}